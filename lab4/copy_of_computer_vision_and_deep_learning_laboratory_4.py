# -*- coding: utf-8 -*-
"""Copy of Computer Vision and Deep Learning - Laboratory 4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gJ0jChLSqTfWu0CJqkVJHfK-CdRge7Ab

# Computer Vision and Deep Learning - Laboratory 4
 
The main objective of this laboratory is to familiarize you with the training process of a neural network. More specifically, you'll follow this ["recipe"](!http://karpathy.github.io/2019/04/25/recipe/) for training  neural networks proposed by Andrew Karpathy.
You'll go through all the steps of training, data preparation, debugging, hyper-parameter tuning.
 
In the second part of the laboratory, you'll experiment with _transfer learning_ and _fine-tuning_.  Transfer learning is a concept from machine learning which allows you to reuse the knowledge gained while solving a problem (in our case the CNN weights) and applying it to solve a similar problem. This is useful when you are facing a classification problem with a small training dataset.
"""

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import cv2

"""# Data loading. Training a neural network. Tuning hyper-parameters. 

Your task for the first part of the laboratory is to train a convolutional nerual network for image classification. You can choose any dataset for image classification. By default you can use the [Oxford Pets dataset](!https://www.robots.ox.ac.uk/~vgg/data/pets/), but you can choose a dataset that you will be using for your project or an interesting dataset from [Kaggle](!https://www.kaggle.com/datasets?search=image).

So the first step would be download your training data.
"""

"""## Data loading 
 
Up until now, we could load the data to train our model in a single line of code: we just used numpy.load to read the entire training and test sets into memory.
However, in some cases we won't be able to fit all the data into the memory due to hardware constraints.
 
To alleviate this problem, we'll use the [_Sequence_](!https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence) class from tensorflow which allows us to feed data to our models.
To write a custom data generator, you'll have to 
- write a class that inherits from the class _Sequence_
- override the \_\_len\_\_ method: this method should return the number of batches in a sequence. In this method you can just return the value:
\begin{equation}
len = \frac{training\_samples}{batch\_size}
\end{equation}
- override the \_\_get_item\_\_(self, index) method: this should return a complete batch;
- optionally, you can override other methods, such as on_epoch_end(). For example, here you could shuffle the data after each epoch.
 
What's nice about this is that when calling the fit() method on a model with a _Sequence_, you can set the use_multiprocessing to True and use several workers that will generate the training batches in parallel.
 
``
fit(
    x=None, y=None, batch_size=None, epochs=1, verbose='auto',
    callbacks=None, validation_split=0.0, validation_data=None, shuffle=True,
    class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None,
    validation_steps=None, validation_batch_size=None, validation_freq=1,
    max_queue_size=10, workers=1, use_multiprocessing=False
)
``
 
Start by writing a custom data generator for the dataset that you chose.


"""

def resize_image(image, width = None, height = None, inter = cv2.INTER_AREA):
    # initialize the dimensions of the image to be resized and
    # grab the image size
    dim = None
    (h, w) = image.shape[:2]

    # if both the width and height are None, then return the
    # original image
    if width is None and height is None:
        return image

    # check to see if the width is None
    if width is None:
        # calculate the ratio of the height and construct the
        # dimensions
        r = height / float(h)
        dim = (int(w * r), height)

    else:
        # calculate the ratio of the width and construct the
        # dimensions
        if w > h:
            r = width / float(w)
            dim = (width, int(h * r))
        else: 
            r = height / float(h)
            dim = (int(w * r), height)

    # resize the image
    resized = cv2.resize(image, dim, interpolation = inter)

    # return the resized image
    return resized


#this function is used to resize the image to 32x32 and to create a border of type replicate
def process_image(path):
    image = cv2.imread(path)
    if image is None:
        return
    image = resize_image(image, 32, 32)
    top = bottom = (32 - image.shape[0]) // 2
    left = right = (32 - image.shape[1]) // 2
    bottom = bottom + 1 if top + bottom + image.shape[0] < 32  else bottom
    right = right + 1 if left + right + image.shape[1] < 32 else right
    image = cv2.copyMakeBorder(image, top,bottom,left,right, cv2.BORDER_REPLICATE)
    return image


class DataGenerator(tf.keras.utils.Sequence):
    def __init__(self, db_dir, batch_size, input_shape, num_classes, 
                 shuffle=True):
        # TODO your initialization
        # you might want to store the parameters into class variables
        self.input_shape = input_shape
        self.batch_size = batch_size
        self.num_classes = num_classes
        self.shuffle = shuffle
        self.db_dir = db_dir
        # load the data from the root directory
        self.data, self.labels = self.get_data(db_dir)
        self.indices = np.arange(len(self.data))
        self.on_epoch_end()

    def get_data(self, root_dir):
        """
        Loads the paths to the images and their corresponding labels from the database directory
        """
        # TODO your code here
        self.data = []
        self.labels = []
        with open('labels.txt', 'r') as f:
            for line in f.readlines():
                splitted = line.split()
                self.data.append("./{0}/".format(root_dir) + splitted[0] + ".jpg")
                self.labels.append(int(splitted[1]))
        return self.data, self.labels

    def __len__(self):
        """
        Returns the number of batches per epoch: the total size of the dataset divided by the batch size
        """
        return int(np.floor(len(self.data) / self.batch_size))
       

    def __getitem__(self, index):
        """
        Generates a batch of data
        """
        batch_indices = self.indices[index*self.batch_size : (index+1)*self.batch_size]
        for index in batch_indices:
            img = cv2.imread(self.data[index])
            dimensions = img.shape
            
        batch_x = [cv2.cvtColor(process_image(self.data[index]), cv2.COLOR_BGR2RGB) for index in batch_indices] # TODO load the image from batch_indices
        batch_y = [self.labels[index] - 1 for index in batch_indices] # TODO load the corresponding labels of the images you loaded
        # optionally you can use: batch_y = tf.keras.utils.to_categorical(batch_y, num_classes=self.num_classes)
        return np.array(batch_x), np.array(batch_y)

    def on_epoch_end(self):
        """
        Called at the end of each epoch
        """
        # if required, shuffle your data after each epoch
        self.indices = np.arange(len(self.data))
        if self.shuffle:
            # TODO shuffle data
            # you might find np.random.shuffle useful here
            np.random.shuffle(self.indices)

"""Now let's look at some images and samples from our data generator."""

label_names = [None for _ in range(38)]
with open('labels.txt', 'r') as f:
    for line in f.readlines():
        splitted = line.split()
        label_idx = int(splitted[1])
        label_names[label_idx] = splitted[0][0: splitted[0].rindex('_')]

train_generator = DataGenerator( db_dir = "./images", input_shape = (32, 32, 3), num_classes = 37, 
    batch_size=32, shuffle=True)

batch_x, batch_y = train_generator[0]

fig, axes = plt.subplots(nrows=1, ncols=6, figsize=[16, 9])
for i in range(len(axes)):
    axes[i].set_title(label_names[batch_y[i] + 1])
    axes[i].imshow(batch_x[i])
plt.show()

"""# CNN architecture

Write a simple tensorflow architecture for a convolutional neural network.
Use the [functional](!https://www.tensorflow.org/guide/keras/functional) api when writing the model.

"""

from tensorflow.keras.layers import *
from tensorflow.keras.initializers import he_normal
from tensorflow.keras.activations import softmax
from tensorflow.keras import Model

def res_block(inputs, filters):
    x = Conv2D(filters, 3, padding='same', activation='relu', kernel_initializer = he_normal())(inputs)
    x = Conv2D(filters, 3, padding='same', activation='relu', kernel_initializer = he_normal())(x)
    return x + inputs

inputs = Input(shape=(32, 32, 3))
print(inputs.shape)
x = Conv2D(32, 3, padding='same', activation='relu', kernel_initializer = he_normal())(inputs)
x = res_block(x, 32)
x = MaxPooling2D()(x)
x = Conv2D(64, 3, padding='same', activation='relu', kernel_initializer = he_normal())(x)
x = res_block(x, 64)
x = MaxPooling2D()(x)
x = Conv2D(128, 3, padding='same', activation='relu', kernel_initializer = he_normal())(x)
x = res_block(x, 128)
x = GlobalAveragePooling2D()(x)
outputs = Dense(37, activation=softmax)(x)

from tensorflow.keras import Model
model = Model(inputs=inputs, outputs=outputs)
model.summary()



"""## Training and fine-tuning

Start by reading this blog [post](!http://karpathy.github.io/2019/04/25/recipe/), such that you can get an idea of the pipeline that you'll have to follow when training a model.

- Triple check that your data loading is correct. (Analyse your data.)
- Check that the setup is correct.
- Overfit a simple network.
- Add regularizations.
  - data augmentation
  - weight decay

Finetune the learning rate. Use learning rate decay; here in the [documentation](!https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/LearningRateSchedule) you have an example on how you can use a learning rate scheduler in tensorflow.

You should have at least 7 different trainings. Plot all the training history.

__Save all your models and their training history!__ 


Create a google spreadsheet or a markdown table in this notebook, and report the configuration and the accuracy for all these trains. 

### Other useful videos (bias and variance, basic recipe for training a deep NN)
- https://www.youtube.com/watch?v=NUmbgp1h64E 
- https://www.youtube.com/watch?v=SjQyLhQIXSM&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&index=2 
- https://www.youtube.com/watch?v=C1N_PDHuJ6Q&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&index=3 

"""

inputs = Input(shape=(32, 32, 3))
print(inputs.shape)
x = Conv2D(32, 3, padding='same', activation='relu', kernel_initializer = he_normal())(inputs)
x = res_block(x, 32)
x = MaxPooling2D()(x)
x = Conv2D(64, 3, padding='same', activation='relu', kernel_initializer = he_normal())(x)
x = res_block(x, 64)
x = MaxPooling2D()(x)
x = Conv2D(128, 3, padding='same', activation='relu', kernel_initializer = he_normal())(x)
x = res_block(x, 128)
x = GlobalAveragePooling2D()(x)
outputs = Dense(37, activation=softmax)(x)

model = Model(inputs=inputs, outputs=outputs)
model.summary()
opt = tf.keras.optimizers.Adam(learning_rate=0.005)

model.compile(
    loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer=opt,
    metrics=['accuracy']
)

history = model.fit_generator(generator=DataGenerator(db_dir = "./images", input_shape = (32, 32, 3), num_classes = 37, batch_size=128, shuffle=True), epochs=10, verbose=1)

"""### **Extra credit**

Implement the learning rate scheduler described in the [paper](!https://arxiv.org/pdf/1608.03983.pdf) "SGDR: Stochastic gradient descent with warm restarts". You are mostly interested in Section 3 from the paper.
"""

# TODO optional extra credit assignment

"""## Ensembles
 
Pick your N (3 or 5) of the networks that you've trained and create an ensemble. The prediction of the ensemble is just the average of the predictions of the N networks.
 
Evaluate the ensemble (your accuracy should boost by at least 1.5%).

"""

# TODO your code here
# feed the images to the three networks, average the logits of the networks and 

# evaluate the ensemble

"""# Transfer learning and fine-tuning
 
In the _tensorflow.keras.applications_ module you can find implementations of several well known CNN architectures (most of the models that we covered during the lecture), as well as the pretrained weights of these models on the ImageNet dataset. 
You can use this module to apply transfer learning and fine-tuning for your classification problem. [Here](!https://keras.io/api/applications/) you can find a comprehensive table with the size of the models, number of parameters, top-1 and top-5 accuracy on the ImageNet dataset.
 
When using deep neural networks, transfer learning is the norm, not the exception.  Transfer learning refers to the situation where what has been learned in one setting is used to improve generalization in another setting.
The transfer learning pipeline can be summarized as follows:
- get the weights of a model trained on similar classification problem (for which more training data is available);
- remove the final classification layer;
- freeze the weights (don't update them during the training process); these layers would be used as a feature extractor;
- add a/some trainable layers over the frozen layers. They will learn how the extracted features can be used to distinguish between the classes of your classification problem.
- train these new layers on your dataset.
 
Next, you can also use fine-tuning. During fine-tuning you will unfreeze the model (or a larger part of the model), and train it on the new data with a very low learning rate.
 
Follow this [tutorial](!https://keras.io/guides/transfer_learning/) to solve this exercise.
 
When following the tutorial
- pay attention to the discussion about the BatchNormalization layers;
- you can skip the section "Transfer learning & fine-tuning with a custom training loop", we'll cover this in the next laboratory;
- pay attention to the loss that you will be using when training your model. In the tutorial the loss is the binary cross entropy loss which is suitable for binary classification problems. If your problem is multi-class you should use the categorical cross entropy loss.
- use the pre-processing required by the network architecture that you chose.
 
To sum up, pick a neural network architecture from the _tensorflow.keras.applications_ module and use transfer learning and fine tuning to train it to classify the images from your dataset (you should use the custom DataGenerator that you wrote for this). 
 Briefly describe the key features of the neural network architecture that you chose and why you chose it.
 
Apply transfer learning (with at least one config for the hyperparameters) and report the performance. Apply fine-tuning  (with at least one config for the hyperparameters) and report the performance.
Finally, plot the performance of the model when you used only transfer learning and the performance of the model when you also used fine-tuning on the same plot.
 
I chose the architecture <font color='red'> TODO </font> , because <font color='red'> TODO </font> .
The key features of this architecture are
- <font color='red'> TODO  </font> 
- <font color='red'> TODO  </font> 
- <font color='red'> TODO  </font> 
 
How does the performance of this fine-tuned model compare to the performance of the network that you trained from scratch?
 
"""

# TODO your transfer-learning and fine-tuning step
import ssl

ssl._create_default_https_context = ssl._create_unverified_context

mobile_model = tf.keras.applications.MobileNetV2(
    input_shape=(32, 32, 3),
    include_top=False,
    weights="imagenet",
)

mobile_model.summary()


out = mobile_model.get_layer('block_5_project')
non_trainable = tf.keras.Model(inputs=mobile_model.input, outputs=out.output)
non_trainable.trainable = False
x = non_trainable(inputs)
x = tf.keras.layers.Conv2D(128, (2, 2), padding='valid', strides=(2, 2), activation='relu', kernel_initializer=he_normal())(x)
x = tf.keras.layers.Conv2D(37, (1, 1), padding='same', activation='relu', kernel_initializer=he_normal())(x)
x = GlobalAveragePooling2D()(x)
outputs = Dense(37, activation=softmax)(x)
model_tranfer_learning = tf.keras.Model(inputs=inputs, outputs=outputs)
model_tranfer_learning.summary()





